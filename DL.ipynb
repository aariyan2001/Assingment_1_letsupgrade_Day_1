{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHn3EVbz7MdwdRis/0gPvZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aariyan2001/Assingment_1_letsupgrade_Day_1/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "71Pu3qUp1DKI"
      },
      "outputs": [],
      "source": [
        "#Hello world to neural network (A simple neural network to find relationship between x and y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "xs = np.array([-1.0,0.0,1.0,2.0,3.0,4.0], dtype=float)\n",
        "ys = np.array([-3.0,-1.0,1.0,3.0,5.0,7.0], dtype=float)\n"
      ],
      "metadata": {
        "id": "wgdvDIBT0xFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#we have only one layer here\n",
        "model = keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
        "model.compile(optimizer=\"sgd\" , loss = \"mean_squared_error\")\n",
        "model.fit(xs,ys, epochs=500)  #epoches 500 means it goes through the training loop 500 times\n",
        "print(model.predict([10.0]))\n"
      ],
      "metadata": {
        "id": "wpjrR6G82iO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using fashion-MINIST clothes dataset to make a neural network.\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "Z-XNm-Lh0VIG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code to visualize the image with its pixel values who is ranging from 0-255\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#you can put the image index here since we have 60,000 images so the index will be from 0 - 59999\n",
        "index = 42\n",
        "\n",
        "# Set number of characters per row when printing\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "#Print the label and image\n",
        "print(f'Label: {train_labels[index]}')\n",
        "print(f'\\nImage Pixel Array:\\n {train_images[index]}')\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(train_images[index], cmap=\"Greys\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "9sfN-Nil5kyB",
        "outputId": "5ae66a4f-dad0-45cc-de2f-f4c00131c14d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n",
            "\n",
            "Image Pixel Array:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187  26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237 255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234 238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237 235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239 238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241 240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241 242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241 244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241 242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242 241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237 236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231 232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230 228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250 251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227 219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184 152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0   0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0   0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f94261f9cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since neural network works better with normalized data so we will normalize the pixel value from 0-255 to between 0-1\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0 "
      ],
      "metadata": {
        "id": "dbb56Eul7skQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have three layers in sequential \n",
        "#model = keras.Sequential([\n",
        "#    keras.layers.Flatten(input_shape = (28, 28)), #it is the first layer specifiying the shape that we should expect the data to be in\n",
        "#    keras.layers.Dense(128, activation = tf.nn.relu), #this is a middle layer with 128 neurons \n",
        "#    keras.layers.Dense(10, activation = tf.nn.softmax) #this is the last layer having 10 neurons because we have 10 labels of clothes(they should always match)\n",
        "#])\n",
        "\n",
        "#The flattern takes this 28by28 square or pixels and turns it into a simple linear array\n",
        "model = tf.keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape = (28, 28)), #it is the first layer specifiying the shape that we should expect the data to be in\n",
        "    keras.layers.Dense(128, activation = tf.nn.relu), #this is a middle layer with 128 neurons\n",
        "    keras.layers.Dense(10, activation = tf.nn.softmax) #this is the last layer having 10 neurons because we have 10 labels of clothes(they should always match)\n",
        "])"
      ],
      "metadata": {
        "id": "lXYQVkF52Zk6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential : That defines a sequence of layers in the neural network\n",
        "\n",
        "Flatten: It takes this 28by28 square or pixels of images and turns it into a simple linear array with pixel value from 0-255\n",
        "\n",
        "Dense : adds a layer of neurons\n",
        "\n",
        "Each layer requires an activation function here we have used relu and softmax"
      ],
      "metadata": {
        "id": "9WaceUt58pKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(), #optimizer = \"Adam\"\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs = 5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ-W1kzt5aCN",
        "outputId": "857fd54f-f0d0-47f5-f4a4-543724d59441"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2507 - accuracy: 0.9067\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2417 - accuracy: 0.9077\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2332 - accuracy: 0.9118\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2267 - accuracy: 0.9147\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2236 - accuracy: 0.9153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9413af5fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now to stop the triaining at certain epochos where we get our desired result and without going through\n",
        "# all the epochos computation, we can use callback() function, so on every epochos we can callback\n",
        "# a code function having checked the metrics, and if you get the desired result then cancel at\n",
        "# that point.\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nLoss is low so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(), #optimizer = \"Adam\"\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs = 5, callbacks = [callbacks])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uM5D99HCkNc",
        "outputId": "72185965-4d3a-4bbb-8263-82d5e6aaa7e9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9176\n",
            "Loss is low so cancelling training!\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2167 - accuracy: 0.9176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9426126310>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model on unseen data\n",
        "model.evaluate(test_images, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3sbMooK1e_r",
        "outputId": "339148f9-a192-4adb-eecd-b84dac426ff4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3426 - accuracy: 0.8803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.342592716217041, 0.880299985408783]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It creates a set of classifications for each of the test images, and then prints the first entry in the classifications\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0]) #It's the probability that this item (0) is each of the 10 classes\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_m_G67K_E1w",
        "outputId": "68e736e8-7b57-4a72-c05c-59add4d811ff"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 1ms/step\n",
            "[4.4057501e-06 2.7440944e-10 2.1825958e-08 1.3404684e-07 1.2914740e-08 5.7644234e-03 3.3299522e-05 5.5521525e-02 6.8759596e-06 9.3866932e-01]\n",
            "9\n"
          ]
        }
      ]
    }
  ]
}